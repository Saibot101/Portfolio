import{V as A,a as $,C as G,P,b as S,c as O}from"./VList.a8f27c7e.js";import{_ as k,l as c,ae as f,k as t,h as e,p as n,af as j,ag as h,G as b,s as F,z as x,t as g,m as s,j as m,ah as T,F as v,ai as E,aj as y,i as D,ak as K,al as p}from"./index.fe645947.js";import"./forwardRefs.8760e9ba.js";import"./getScrollParent.ff47518e.js";const V={props:{code_array:{required:!0,type:Array}},data(){return{codeArray:this.code_array,snackbar:!1}},methods:{copyClipboard(){this.snackbar=!0;let o="";for(let l of this.codeArray)o=o+l+` 
`;navigator.clipboard.writeText(o)}}},W={class:"mt-2 mb-4"};function L(o,l,C,I,u,d){return c(),f(n,{justify:"center"},{default:t(()=>[e(E,{width:"750",color:"blue-grey darken-4",outlined:"",elevation:"8",rounded:"",class:"mb-5"},{default:t(()=>[e(n,null,{default:t(()=>[e(j,{class:"mt-3"},{default:t(()=>[e(h,{color:"red",size:"12",class:"ml-5"}),e(h,{color:"yellow",size:"12",class:"ml-2"}),e(h,{color:"green",size:"12",class:"ml-2"})]),_:1}),e(A),e(b,{icon:"",class:"mt-5 mr-5",onClick:d.copyClipboard},{default:t(()=>[e(F,{color:"black",icon:"mdi-content-copy"})]),_:1},8,["onClick"]),e($,{modelValue:u.snackbar,"onUpdate:modelValue":l[1]||(l[1]=a=>u.snackbar=a),timeout:"2000",color:"blue-grey darken-4 white--text"},{action:t(({attrs:a})=>[e(b,x({color:"pink",text:""},a,{onClick:l[0]||(l[0]=r=>u.snackbar=!1)}),{default:t(()=>[g(" Close ")]),_:2},1040)]),default:t(()=>[g(" Copied to Clipboard ")]),_:1},8,["modelValue"])]),_:1}),e(n,{justify:"start",class:"mb-3 ml-10 mr-4"},{default:t(()=>[s("div",W,[(c(!0),m(v,null,T(u.codeArray,(a,r)=>(c(),m("p",{class:"text-body-1 white--text blue-grey darken-4 my-n1",key:r,style:{"white-space":"pre-wrap"}},y(a),1))),128))])]),_:1})]),_:1})]),_:1})}const N=k(V,[["render",L]]),z={name:"CloudPortfolio",components:{CodeSnippet:G,CmdSnippet:N,ParagraphSnippet:P},methods:{scroll(o){document.getElementById(o).scrollIntoView({behavior:"smooth"})}},setup(){D({title:"CI/CD of Cloud Functions including the Service by using Infrastructure as Code",meta:{description:"This tutorial shows how to create a pipeline to automatically push OpenFAAS as a Kubernetes Cluster to Google Cloud."}})},data:()=>({list_inhalt:[{name:"Introduction",scroll:"introduction"},{name:"Google Cloud",scroll:"google"},{name:"Installation Openfaas",scroll:"installation"},{name:"Connection Openfaas",scroll:"connection"},{name:"Creating Functions",scroll:"function"},{name:"Creating finale pipeline",scroll:"new"}],project:['project_id = "project_id"','region       = "europe-west3"'],cluster_nodes:['variable "gke_num_nodes" {',"   default        = 1",'   description = "number of gke nodes"',"}"," ","# GKE cluster",'resource "google_container_cluster" "primary" {','   name     = "${var.project_id}-gke"',"   location = var.region","   remove_default_node_pool = true","   initial_node_count       = 1"," ","   network    = google_compute_network.vpc.name","   subnetwork = google_compute_subnetwork.subnet.name"," }"],node_pool:["# Separately Managed Node Pool",'resource "google_container_node_pool" "primary_nodes" {','   name       = "${google_container_cluster.primary.name}-node-pool"',"   location   = var.region","   cluster    = google_container_cluster.primary.name","   node_count = var.gke_num_nodes"," ","   node_config {","       oauth_scopes = [",'           "https://www.googleapis.com/auth/logging.write",','           "https://www.googleapis.com/auth/monitoring",',"       ]"," ","       labels = {","           env = var.project_id","       }"," ","       # preemptible  = true",'       machine_type = "n1-standard-1"','       tags         = ["gke-node", "${var.project_id}-gke"]',"       metadata = {",'           disable-legacy-endpoints = "true"',"       }","   }","}"],backend_store:["terraform{",'   backend "gcs" {','       bucket = "bucket_name"','       prefix = "terraform/state"',"   }","}"],terraform_apply:["$ terraform apply"],terraform_init:["$ terraform init"],kubernetes_entry:["$ gcloud container clusters get-credentials $(terraform output -raw kubernetes_cluster_name) --region $(terraform output -raw region)"],install_openfaas:["$ arkade install openfaas -load-balancer"],openfaas_password:['export PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath="***.data.basic-auth-password***" | base64 --decode; echo)'],openfaas_ip:['$ export GATEWAY_IP=$(kubectl get service gateway-external -n openfaas -o jsonpath="{.status.loadBalancer.ingress[0].ip}")'],openfaas_store:["$ faas-cli store deploy 'NodeInfo' --gateway http://$GATEWAY_IP:8080"],download_docker:['curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable"'],test_yaml:["version: 1.0","provider:","   name: openfaas","   gateway: http://${URL:-exampleco}:8080","functions:","   test:","       lang: python3","       handler: ./test","       image: repository_name/test:latest"],handler_py:["def handle(req):"," ",'""" handle a request to the function'," ","Args:","req (str): request body",'"""'," ",'return "test function"'],initialization_1:["name: CI"," ","# Controls when the workflow will run","on:","   # Triggers the workflow on push or pull request events but only for the main branch"," ","   push:","       branches: [ main ]","   pull_request:"," ","   # Allows you to run this workflow manually from the Actions tab","   workflow_dispatch:"," ","   jobs:","       setup-and-deploy:","           name: Setup and Deploy","           runs-on: ubuntu-latest"," ",'# Add "id-token" with the intended permissions.',"   permissions:","       contents: 'read'","       id-token: 'write'","   steps:"],initialization_2:["   - name: Checkout","     uses: actions/checkout@v3"," ","   - name: Terraform","     uses: hashicorp/setup-terraform@v2"," ","   - name: Sleep","     uses: jakejarvis/wait-action@master"],initialization_3:["   - id: 'auth'","     name: 'Authenticate to Google Cloud'","     uses: 'google-github-actions/auth@v0'","     with:","         credentials_json: '${{ secrets.GCP_CREDENTIALS }}'"," ","     # Setup gcloud CLI","   - name: Set up Cloud SDK","     uses: google-github-actions/setup-gcloud@v0","   - name: 'Use gcloud CLI'","     run: 'gcloud info'"],initialization_4:["   - name: Login to Docker Hub","     uses: docker/login-action@v1","     with:","         username: ${{ secrets.DOCKER_HUB_USERNAME }}","         password: ${{ secrets.DOCKER_HUB_ACCESS_TOKEN }}"],create_cluster_1:["   - name: Terraform Init","     id: init","     run: terraform init -lock=false"," ","   - name: Terraform Plan","     id: plan","     run: terraform plan -no-color -lock=false","     continue-on-error: true"," ","   - name: Terraform Apply","     run: terraform apply -auto-approve -lock=false"],create_cluster_2:["   - name: Get kubectl Connection","     run: gcloud container clusters get-credentials crypto-parser-350713-gke --region  europe-west1","     continue-on-error: true"],create_cluster_3:["   - name: Install Arkade","     run: curl -sLS https://get.arkade.dev | sudo sh"," ","   - name: Test Arkade","     run: arkade --help"," ","   - name: Install Openfaas","     run: arkade install openfaas --load-balancer","     continue-on-error: true"],create_cluster_4:["   - name: Sleep 2 min","     run: sleep 120s"," ","   - name: Get IP",'     run: echo GATEWAY_IP=$(kubectl get service gateway-external -n openfaas -o jsonpath="{.status.loadBalancer.ingress[0].ip}") >> $GITHUB_ENV',"     continue-on-error: true"," ","   - name: Get Password",'     run: echo PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath="{.data.basic-auth-password}" | base64 --decode; echo) >> $GITHUB_ENV',"     continue-on-error: true"],create_cluster_5:["   - name: Download open-faas cli","     run: curl -sSL https://cli.openfaas.com | sudo -E sh","     continue-on-error: true"," ","   - name: Connect to Openfaas","     run: echo -n ${{env.PASSWORD}} | faas-cli login --username admin --password-stdin --gateway http://${{env.GATEWAY_IP}}:8080","     continue-on-error: true"," ","   - name: Push Test function","     run: faas-cli store deploy 'NodeInfo' --gateway http://${{env.GATEWAY_IP}}:8080","     continue-on-error: true"],add_function_1:["   - name: Get kubectl Connection","     run: gcloud container clusters get-credentials crypto-parser-350713-gke --region europe-west1","     continue-on-error: true"],add_function_2:["   - name: Get IP",'     run: echo GATEWAY_IP=$(kubectl get service gateway-external -n openfaas -o jsonpath="{.status.loadBalancer.ingress[0].ip}") >> $GITHUB_ENV',"     continue-on-error: true"," ","   - name: Get Password",'     run: echo PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath="{.data.basic-auth-password}" | base64 --decode; echo) >> $GITHUB_ENV',"     continue-on-error: true"],add_function_3:["   - name: Download open-faas cli","     run: curl -sSL https://cli.openfaas.com | sudo -E sh","     continue-on-error: true"," ","   - name: Connect to Openfaas","     run: echo -n ${{env.PASSWORD}} | faas-cli login --username admin --password-stdin --gateway http://${{env.GATEWAY_IP}}:8080","     continue-on-error: true"," ","   - name: Upload function","     run: URL=${{env.GATEWAY_IP}} faas-cli up -f test.yml"]})},R=s("h1",{class:"text-center mt-10 mb-5 text-h3"}," CI/CD of Cloud Functions including the Service by using Infrastructure as Code ",-1),U=s("h2",{class:"text-h4"},"Contents",-1),B=s("h2",{class:"text-h4"},"Introduction",-1),Y=s("h3",{class:"text-h5 font-weight-bold"},"OpenFaas",-1),H=s("h3",{class:"text-h5 font-weight-bold"},"CI/CD",-1),q=s("h3",{class:"text-h5 font-weight-bold"},"Github Actions",-1),M=s("h3",{class:"text-h5 font-weight-bold"},"Terraform",-1),J=s("h3",{class:"text-h5 font-weight-bold"},"Kubernetes",-1),Q=s("h3",{class:"text-h5 font-weight-bold"},"Google Cloud",-1),X=s("h2",{class:"text-h4"},"Create a Kuberntes cluster in the Cloud with Terraform",-1),Z=s("h3",{class:"text-h5 font-weight-bold"},"Configure Google Cloud",-1),ee=s("h3",{class:"text-h5 font-weight-bold"},"Configure Kubernetes via Terraform",-1),ae=s("h3",{class:"text-h5 font-weight-bold"},"Get Kubernetes Configuration",-1),te=s("h2",{class:"text-h4"},"Installation Openfaas",-1),oe=s("h2",{class:"text-h4"},"Connection to Openfaas",-1),re=s("h3",{class:"text-h5 font-weight-bold"},"Port-forwarding",-1),ne=s("h3",{class:"text-h5 font-weight-bold"},"Connection over public IP",-1),se=s("h2",{class:"text-h4"},"Creating Functions",-1),ie=s("h3",{class:"text-h5 font-weight-bold"},"Add function from store",-1),le=s("h3",{class:"text-h5 font-weight-bold"},"Add new function",-1),ce=s("h3",{class:"text-h5 font-weight-bold"},"Example function",-1),ue=s("h2",{class:"text-h4"},"Creating finale Pipelines",-1),de=s("h3",{class:"text-h5 font-weight-bold"},"Initialization",-1),he=s("h3",{class:"text-h5 font-weight-bold"},"Create Cluster, install OpenFaas and upload function",-1),pe=s("h3",{class:"text-h5 font-weight-bold"},"Add function to existing cluster",-1);function fe(o,l,C,I,u,d){const a=p("ParagraphSnippet"),r=p("CmdSnippet"),i=p("Code-Snippet");return c(),f(K,null,{default:t(()=>[R,e(n,{justify:"center",class:"mt-10"},{default:t(()=>[U]),_:1}),e(n,{justify:"center"},{default:t(()=>[e(S,{dense:""},{default:t(()=>[(c(!0),m(v,null,T(o.list_inhalt,(_,w)=>(c(),f(O,{key:w,onClick:ge=>d.scroll(_.scroll)},{default:t(()=>[g(y(w+1)+". "+y(_.name),1)]),_:2},1032,["onClick"]))),128))]),_:1})]),_:1}),e(n,{justify:"center",id:"introduction"},{default:t(()=>[B]),_:1}),e(a,{paragraph:"The goal of this blog entry to show and explaine how to use pipelines to create FaaS in an cloud environment and how to automatically install functions in the cluster. In the first part all steps will be explained in a way that you can follow it on your console. In the last stage the structure of the pipeline will be explained. If you are only interested in the pipeline then skip to chapter 5."},null,8,["paragraph"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[Y]),_:1}),e(a,{paragraph:"OpenFaas is an open-source project, which you can use to host your own FaaS."},null,8,["paragraph"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[H]),_:1}),e(a,{paragraph:"This pipeline focuses on the deployment aspects of CI/CD."},null,8,["paragraph"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[q]),_:1}),e(a,{paragraph:"If their are any changes in the terraform code or a function is pushed to the repository, the pipeline will be started and execute the code of the pipeline."},null,8,["paragraph"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[M]),_:1}),e(a,{paragraph:"Terraform is a descriptive language for infrastructure. Terraform is used, to describe the Kubernetes cluster and configure a public IP in the Google Cloud."},null,8,["paragraph"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[J]),_:1}),e(a,{paragraph:"Kubernetes allows to automate, scale and manage container. OpenFaas recommands using Kubernetes instead of a single container. It allows to have the container in different locations in the Google Cloud to increase uptime security."},null,8,["paragraph"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[Q]),_:1}),e(a,{paragraph:"Google Cloud is one of the biggest Cloud Provider. It has a generous credit policy, if you create a new account. The following Kubernetes cluster are paid services and will be deducted from your balance."},null,8,["paragraph"]),e(n,{justify:"center",id:"google"},{default:t(()=>[X]),_:1}),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[Z]),_:1}),e(a,{paragraph:"There are three steps in the initialization process. Firstly, install the Google Cloud SDK to your system."},null,8,["paragraph"]),e(r,{code_array:["$ sudo apt install google-cloud-sdk"]}),e(a,{paragraph:"Secondly, connect your local Google Cloud instance to your GCP account. "},null,8,["paragraph"]),e(r,{code_array:["$ gcloud init"]}),e(a,{paragraph:"Lastly, add the Google Account to the Application Default Credentials, so that Terraform can access the Credentials from Google Cloud."},null,8,["paragraph"]),e(r,{code_array:["$ gcloud auth application-default login"]}),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[ee]),_:1}),e(a,{paragraph:"The Terraform setup is based on a tutorial from Hashicorp. The tutorial can be found under the following link: https://github.com/hashicorp/learn-terraform-provision-gke-cluster. The tutorial is used as a base and will be changed and extended for the need of OpenFaas."},null,8,["paragraph"]),e(r,{code_array:["$ git clone https://github.com/hashicorp/learn-terraform-provision-gke-cluster"]},null,8,["code_array"]),e(a,{paragraph:"If you cloned the repository, change the starting repository for Terraform."},null,8,["paragraph"]),e(r,{code_array:["$ cd learn-terraform-provision-gke-cluster"]}),e(a,{paragraph:"The next step is changing the terraform.tfvars file. Enter your Google Project ID and add the region where you want the cluster to be created."},null,8,["paragraph"]),e(i,{code_array:o.project},null,8,["code_array"]),e(a,{paragraph:"If you do not know your Project_ID, you can get it with the following command."},null,8,["paragraph"]),e(r,{code_array:["$ gcloud config get-value project"]}),e(a,{paragraph:"Describe the number of Google Kubernetes Engine nodes, which will be created in the cloud. In the example from Terraform are two nodes declared. An error will be raised when you use the free trail of Google Cloud. The next resource describes the GKE directly. Define the name and location for the Cluster, set the remove_default_node_pool to true and give an initial number of nodes. Name and location derive from the terraform.tfvars file. The remove_default_node_pool removes the default cluster as creating a cluster on your own increases flexibility and opens options for customization."},null,8,["paragraph"]),e(i,{code_array:o.cluster_nodes},null,8,["code_array"]),e(a,{paragraph:"Next, declare the seperately managed node pool with the google_container_node_pool resource. Again, define the name and location. Then use the cluster and node_count you created earlier. The important information here is the machine_type. The machine_type variable declares the machine used in the Cluster. Machine types vary in their impact on the costs deducted from your Google Cloud account. A more expensive machine will potentially burn through the free trail."},null,8,["paragraph"]),e(i,{code_array:o.node_pool},null,8,["code_array"]),e(a,{paragraph:"For the state management you can also use Google Cloud. To store the state of the system you need the right functioning of Terraform. If you want to store your state in the Google Cloud, you can create a Google Cloud Storage. Then add your bucket name in the file below. You can also save the state at another provider but then you need to change the code snippet below."},null,8,["paragraph"]),e(i,{code_array:o.backend_store},null,8,["code_array"]),e(a,{paragraph:"The command \u201Cterraform init\u201D gets the state and providers initialized."},null,8,["paragraph"]),e(r,{code_array:o.terraform_init},null,8,["code_array"]),e(a,{paragraph:"\u201Capply\u201D executes the terraform script and creates the cluster."},null,8,["paragraph"]),e(r,{code_array:o.terraform_apply},null,8,["code_array"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[ae]),_:1}),e(a,{paragraph:"For the pipeline, add the kubeconfig from the created Cluster in the Google Cloud, so that you can access the cluster and install OpenFaas into it. To do that, download the Kubernetes Commandline tool."},null,8,["paragraph"]),e(r,{code_array:["$ sudo apt install kubectl"]}),e(a,{paragraph:"Then, get the kubeconfig from Google and save it to your local system."},null,8,["paragraph"]),e(r,{code_array:o.kubernetes_entry},null,8,["code_array"]),e(n,{justify:"center",id:"installation"},{default:t(()=>[te]),_:1}),e(a,{paragraph:"The next step in the process is the installation of OpenFaas. Use the Arkade downloader from OpenFaas. Arkade is a marketplace for different Kubernetes services."},null,8,["paragraph"]),e(r,{code_array:["$ curl -sLS https://get.arkade.dev | sudo sh "]},null,8,["code_array"]),e(a,{paragraph:"OpenFaas uses the kubeconfig for the installation, which you installed previously. Also, it is necessary to use the load-balancer from OpenFaas which connects to the Services from Google Cloud to use their public IP service."},null,8,["paragraph"]),e(r,{code_array:o.install_openfaas},null,8,["code_array"]),e(n,{justify:"center",id:"connection"},{default:t(()=>[oe]),_:1}),e(a,{paragraph:"There are two options to connect to the installed OpenFaas installation. The first one is to use the port-forward from Kubernetes and the second option is to connect over the public IP. To do this, install the OpenFaas Commandline tool."},null,8,["paragraph"]),e(r,{code_array:["$ curl -sSL https://cli.openfaas.com | sudo sh"]},null,8,["code_array"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[re]),_:1}),e(a,{paragraph:"The port-forwarding of the cluster is only possible if the installation process of OpenFaas is completed. This can be checked with the following command."},null,8,["paragraph"]),e(r,{code_array:["$ kubectl rollout status -n openfaas deploy/gateway"]}),e(a,{paragraph:"Next, forward the 8080 port of the Kubernetes cluster to your local 8080 port. You need to choose the 8080 port because that is the standard port on which OpenFaas is listening."},null,8,["paragraph"]),e(r,{code_array:["$ kubectl port-forward -n openfaas svc/gateway 8080:8080 &"]}),e(a,{paragraph:"For the login to OpenFaas you need the password. That can be retrieved with the Kubernetes command inside the brackets. To make it easier, you should save it into a variable on your system."},null,8,["paragraph"]),e(r,{code_array:o.openfaas_password},null,8,["code_array"]),e(a,{paragraph:"With the retrieved password you can now login as admin into your OpenFaas cluster."},null,8,["paragraph"]),e(r,{code_array:["echo -n $PASSWORD | faas-cli login --username admin --password-stdin"]}),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[ne]),_:1}),e(a,{paragraph:"The second option to connect to OpenFaas is over a public IP which is not that different to the port-forwarding method. As the first step you need to get the public IP from your cluster. That can be achieved with the following command in the brackets. There should be no differences between different cloud service providers."},null,8,["paragraph"]),e(r,{code_array:o.openfaas_ip},null,8,["code_array"]),e(a,{paragraph:"Then, retrieve the password from the cluster."},null,8,["paragraph"]),e(r,{code_array:o.openfaas_password},null,8,["code_array"]),e(a,{paragraph:"The difference in the login is the flag of the gateway. The default parameter of the faas-cli program in the port-forwarding option is your localhost on port 8080. If the flag were different, the program would try to connect to public address. The gateway IP you retrieved from the previous command is extended with the port 8080, on which OpenFaas will listen."},null,8,["paragraph"]),e(r,{code_array:["$ echo -n $PASSWORD | faas-cli login --username admin --password-stdin --gateway http://$GATEWAY_IP:8080 "]}),e(n,{justify:"center",id:"function"},{default:t(()=>[se]),_:1}),e(a,{paragraph:"There are two ways to add functions to your OpenFaas cluster. The first one is to add a function from the community store and the second one is to create a new function."},null,8,["paragraph"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[ie]),_:1}),e(a,{paragraph:"The store is a collection of pre-build functions, which are created by the community. These are open-source and can be found under the following address: https://github.com/openfaas/store. These functions are hosted in public docker repositories and can be added via the command line or the user interface. One example function, which is used below, gives information about the nodes in the Kubernetes cluster. If the function is called, it will return the number of CPUs, hostname, OS and uptime."},null,8,["paragraph"]),e(r,{code_array:o.openfaas_store},null,8,["code_array"]),e(a,{paragraph:"How you interact with the installed function depends on which connection variant you choose. This tutorial assumes, that you use a public IP. Therefore, you can call the function over its specific URL."},null,8,["paragraph"]),e(r,{code_array:["$ curl $GATEWAY_IP/functions/NodeInfo"]}),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[le]),_:1}),e(a,{paragraph:"If you want to create your own function, you need to install Docker to your local system."},null,8,["paragraph"]),e(r,{code_array:o.download_docker},null,8,["code_array"]),e(a,{paragraph:"After the installation, connect your local docker instance to a public docker repository. If you do not have an account at a public docker repository, you can create it here: https://hub.docker.com/. Then, log in with the following command."},null,8,["paragraph"]),e(r,{code_array:["$ docker login --username user --password password"]}),e(a,{paragraph:"OpenFaas uses templates for the different programming languages. If you want to know, how many templates exist in which language in OpenFaas, use this link: https://docs.openfaas.com/cli/templates/#template-store."},null,8,["paragraph"]),e(r,{code_array:["$ faas-cli template pull"]}),e(a,{paragraph:"This part shows the theoretical process of creating a new template. The section below shows the process of creating a python function. With the following command OpenFaas will create a yaml file, which contains the configuration of the function and a folder with files for the specific language."},null,8,["paragraph"]),e(r,{code_array:["$ faas-cli new function-name --lang template"]}),e(a,{paragraph:"Then, upload your function to your OpenFaas cluster. This process consists of three sub- commands. The rst command is build, where OpenFaas builds a docker image with the language speci c information in it. The second step is pushing the built docker image to your public docker repository. Finally, the docker image gets deployed in your Kubernetes cluster."},null,8,["paragraph"]),e(r,{code_array:["$ faas-cli up -f function-name.yml"]},null,8,["code_array"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[ce]),_:1}),e(a,{paragraph:"The process of creating a function is shown by the example of a python3 function.  Firstly, create the yaml and folder with the following command. You can change the name of the function from test to anything you want."},null,8,["paragraph"]),e(r,{code_array:["$ faas-cli new test --lang python3"]}),e(a,{paragraph:"Next, modify the previously created test.yml file. If your OpenFaas cluster is connected to a static URL, insert the gateway line into your url. If you only have the IP from your Cloud provider, it will be a lot easier for the automation, if you use a docker variable instead of hardcoding the IP into the configuration. The variable is given in the up command from OpenFaas. The second important change is the parameter image. There you define, where the docker image will be saved. The first parameter is the docker_id, the second is the repository name."},null,8,["paragraph"]),e(i,{code_array:o.test_yaml},null,8,["code_array"]),e(a,{paragraph:"The code of the function is defined in the file test/handler.py. In this example it will only return a string as response. Therefore, you do not need to add your used packages in the requirements.txt file. The python compiler will look into this file, determine which packages you used and on which version they are, so they can be downloaded."},null,8,["paragraph"]),e(i,{code_array:o.handler_py},null,8,["code_array"]),e(a,{paragraph:"To finish the creation process you need to upload the function. Here you mention the gateway IP, so that it can be inserted in the test.yml file."},null,8,["paragraph"]),e(r,{code_array:["$ URL=$GATEWAY_IP faas-cli up -f test.yml"]},null,8,["code_array"]),e(n,{justify:"center",id:"new"},{default:t(()=>[ue]),_:1}),e(a,{paragraph:"To make the pipeline more readable and understandable, it is split into logical steps. There are two pipelines with two different tasks. There is a lot of overlap, so it is split into three parts. Both pipelines use the same initialization phase and differ afterwards."},null,8,["paragraph"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[de]),_:1}),e(a,{paragraph:"The first part is the configuration of Github specific settings. These can change depending on the pipeline provider. This defines on which branches the pipeline should trigger or which os it will run."},null,8,["paragraph"]),e(i,{code_array:o.initialization_1},null,8,["code_array"]),e(a,{paragraph:"The next section defines the packages, which will later be used. Depending on which pipeline you implement, not all packages need to be defined."},null,8,["paragraph"]),e(i,{code_array:o.initialization_2},null,8,["code_array"]),e(a,{paragraph:"To get a connection to Google Cloud inside the pipeline you need to download your specific credentials from Google Cloud. Then, add the credentials as secrets in your Github repository. When the step is executed, it will take the credentials from the secrets."},null,8,["paragraph"]),e(i,{code_array:o.initialization_3},null,8,["code_array"]),e(a,{paragraph:"You only need this section, if you want to create a new function. With the docker package, username and access_token you can get access to your docker hub account."},null,8,["paragraph"]),e(i,{code_array:o.initialization_4},null,8,["code_array"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[he]),_:1}),e(a,{paragraph:"For creating the cluster, the pipeline executes \u201Cterraform apply\u201D. It is important to add the flag auto-approve because you cannot do it by hand. This step can take around 20 minutes."},null,8,["paragraph"]),e(i,{code_array:o.create_cluster_1},null,8,["code_array"]),e(a,{paragraph:"After the cluster is created, the pipeline receives the kubeconfig credentials from Google Cloud and saves them locally."},null,8,["paragraph"]),e(i,{code_array:o.create_cluster_2},null,8,["code_array"]),e(a,{paragraph:"With the credentials the pipeline will install OpenFaas into the cluster."},null,8,["paragraph"]),e(i,{code_array:o.create_cluster_3},null,8,["code_array"]),e(a,{paragraph:"It is possible, that the pipeline goes to the next step because some process in the background takes longer. That happens especially when using the IP address. Therefore, the pipeline waits 2 minutes to be sure, that everything is loaded and configured. After the waiting time the pipeline retrieves the IP and password from the pipeline."},null,8,["paragraph"]),e(i,{code_array:o.create_cluster_4},null,8,["code_array"]),e(a,{paragraph:"As the last step the pipeline will connect to OpenFaas and will install a function from the store as proof of work."},null,8,["paragraph"]),e(i,{code_array:o.create_cluster_5},null,8,["code_array"]),e(n,{justify:"center",class:"mt-5"},{default:t(()=>[pe]),_:1}),e(a,{paragraph:"This pipeline only works if there is an OpenFaas cluster running at your cloud provider. Firstly, the pipeline gets the Kubernetes credentials from Google Cloud."},null,8,["paragraph"]),e(i,{code_array:o.add_function_1},null,8,["code_array"]),e(a,{paragraph:"Then, it receives the IP and password for the OpenFaas connection."},null,8,["paragraph"]),e(i,{code_array:o.add_function_2},null,8,["code_array"]),e(a,{paragraph:"Lastly, upload the new function to the OpenFaas cluster. The function code and configuration file need to be in the Github repository. Currently, the pipeline cannot differentiate between different functions in the same repository. This pipeline is only a proof of work and needs to be extended for further tasks."},null,8,["paragraph"]),e(i,{code_array:o.add_function_3},null,8,["code_array"])]),_:1})}const be=k(z,[["render",fe]]);export{be as default};
